{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import sys\n",
    "import import_ipynb\n",
    "from pathlib import Path\n",
    "\n",
    "wgan_dir = Path('notebooks')\n",
    "sys.path.insert(0, str(wgan_dir.resolve()))\n",
    "import wgan\n",
    "import globals\n",
    "import ebm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([globals.IMAGE_SIZE, globals.IMAGE_SIZE]), # Resizing images to 64 x 64\n",
    "    transforms.ToTensor(), # Converting images to tensors\n",
    "])\n",
    "traindataset = LoadDataset(root_dir = '../data/SARscope/train/', transform = transform)\n",
    "testdataset = LoadDataset(root_dir = '../data/SARscope/test/', transform = transform)\n",
    "validdataset = LoadDataset(root_dir = '../data/SARscope/valid/', transform = transform)\n",
    "\n",
    "\n",
    "trainloader = DataLoader(dataset = traindataset, batch_size = globals.BATCH_SIZE, shuffle = True)\n",
    "testloader = DataLoader(dataset = testdataset, batch_size = globals.BATCH_SIZE, shuffle = True)\n",
    "validloader = DataLoader(dataset = validdataset, batch_size = globals.BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wgan.Generator()\n",
    "critic = wgan.Critic()\n",
    "critic_optimizer = torch.optim.Adam(params = critic.parameters(), lr = globals.LEARNING_RATE_CRITIC, betas = (globals.ADAM_BETA_1, globals.ADAM_BETA_2))\n",
    "generator_optimizer = torch.optim.Adam(params = generator.parameters(), lr = globals.LEARNING_RATE_GENERATOR, betas = (globals.ADAM_BETA_1, globals.ADAM_BETA_2))\n",
    "\n",
    "\n",
    "wgan = wgan.wgan(generator, critic, globals.Z_DIM, globals.GP_WEIGHT, critic_optimizer, generator_optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_images(generator, epoch, num_images = 1):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(size = (num_images, globals.Z_DIM))\n",
    "        generated_images = generator(z)\n",
    "    generated_images = (generated_images + 1) / 2\n",
    "    generated_images = torch.squeeze(generated_images,0).numpy().transpose(1,2,0)\n",
    "    plt.imshow(generated_images)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = ebm.EBM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        #critic_optimizer.zero_grad()\n",
    "        #generator_optimizer.zero_grad()\n",
    "\n",
    "        #inputs = data\n",
    "        loss = ebm(data)\n",
    "        #c_loss, g_loss, c_gp, c_wass_loss = wgan(inputs)\n",
    "\n",
    "        print('Batch number {}'.format(i))\n",
    "        #print('Critical loss is {}'.format(c_loss))\n",
    "        #print('Generator loss is {}'.format(g_loss))\n",
    "        #print('Critic GP loss is {}'.format(c_gp))\n",
    "        #print('C_WASS_LOSS is {}'.format(c_wass_loss))\n",
    "\n",
    "\n",
    "        #running_loss += c_loss.item()\n",
    "        #if i % 1000 == 999:\n",
    "         #   last_loss = running_loss / 1000\n",
    "          #  print(' batch {} loss: {}'.format(i + 1, last_loss))\n",
    "           # tb_x = epoch_index * len(trainloader) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            #running_loss = 0\n",
    "    \n",
    "    return last_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/wgan_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "for epoch in range(globals.EPOCHS):\n",
    "    print('EPOCH {}'.format(epoch_number + 1))\n",
    "\n",
    "    ebm.train(True)\n",
    "    #wgan.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    #show_generated_images(generator,epoch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    ebm.eval()\n",
    "    #wgan.eval()\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
