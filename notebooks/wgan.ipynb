{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from globals.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "import import_ipynb\n",
    "dir = Path('notebooks')\n",
    "sys.path.insert(0, str(dir.resolve()))\n",
    "import globals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITIC_STEP = 1\n",
    "Z_DIM = 512\n",
    "LEARNING_RATE_CRITIC = 0.0001\n",
    "LEARNING_RATE_GENERATOR = 0.0001\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "GP_WEIGHT = 25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critic\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = globals.CHANNELS, out_channels = 64, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels = 512, out_channels = 1, kernel_size = 4, stride = 2, padding = 0)\n",
    "\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)     \n",
    "        self.leakyReLU = nn.LeakyReLU(negative_slope = .1)\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.05)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        x = self.conv1(imgs)\n",
    "        x = self.leakyReLU(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim = 1, end_dim = 3)\n",
    "\n",
    "        return x\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv2dtranspose1 = nn.ConvTranspose2d(in_channels = Z_DIM, out_channels = 512, kernel_size = 4, stride = 2, padding = 0, bias = False)\n",
    "        self.conv2dtranspose2 = nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv2dtranspose3 = nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv2dtranspose4 = nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv2dtranspose5 = nn.ConvTranspose2d(in_channels = 64, out_channels = globals.CHANNELS, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self._initialize_weights()\n",
    "\n",
    "        self.leakyReLU = nn.LeakyReLU(negative_slope = .1)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.normal_(m.weight, 0.0, .1)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, latent_space):\n",
    "        batch_size = latent_space.shape[0]\n",
    "        x = torch.reshape(input = latent_space, shape = (batch_size, Z_DIM, 1, 1))\n",
    "\n",
    "        x = self.conv2dtranspose1(x)\n",
    "        x = nn.BatchNorm2d(x.shape[1])(x)\n",
    "        x = self.leakyReLU(x)\n",
    "\n",
    "        x = self.conv2dtranspose2(x)\n",
    "        x = nn.BatchNorm2d(x.shape[1])(x)\n",
    "        x = self.leakyReLU(x)\n",
    "\n",
    "        x = self.conv2dtranspose3(x)\n",
    "        x = nn.BatchNorm2d(x.shape[1])(x)\n",
    "        x = self.leakyReLU(x)\n",
    "\n",
    "        x = self.conv2dtranspose4(x)\n",
    "        x = nn.BatchNorm2d(x.shape[1])(x)\n",
    "        x = self.leakyReLU(x)\n",
    "\n",
    "        x = self.conv2dtranspose5(x)\n",
    "\n",
    "        x = nn.Tanh()(x)\n",
    "        return x\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class WGAN\n",
    "\n",
    "class wgan(nn.Module):\n",
    "    def __init__(self, generator, critic, critic_optimizer, generator_optimizer):\n",
    "        super(wgan, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.critic = critic\n",
    "        self.latent_dim = Z_DIM\n",
    "        self.gp_weight = GP_WEIGHT\n",
    "        self.critic_opt = critic_optimizer\n",
    "        self.generator_opt = generator_optimizer\n",
    "        self.scheduler_critic = torch.optim.lr_scheduler.StepLR(self.critic_opt , step_size = globals.EPOCHS, gamma = 0.999)\n",
    "\n",
    "    \n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        alpha = torch.normal(size = (batch_size, 1, 1, 1), mean = 0.0, std = 1.0)\n",
    "\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = (real_images + alpha * diff).requires_grad_(True)\n",
    "\n",
    "\n",
    "        pred = torch.mean(self.critic(interpolated))\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs = pred,\n",
    "            inputs = interpolated,\n",
    "            grad_outputs = None,\n",
    "            create_graph = True,\n",
    "            retain_graph = True,\n",
    "            only_inputs = True\n",
    "        )[0]\n",
    "\n",
    "\n",
    "\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        gradients_norm = gradients.norm(2, dim = 1)\n",
    "\n",
    "        gp = ((gradients_norm - 1)**2).mean()\n",
    "\n",
    "        return gp\n",
    "    \n",
    "\n",
    "    def forward(self, real_images):\n",
    "        batch_size = real_images.shape[0]\n",
    "\n",
    "\n",
    "        for i in range(CRITIC_STEP):\n",
    "            self.critic_opt.zero_grad()\n",
    "\n",
    "            random_latent_vectors = torch.randn(size = (batch_size, self.latent_dim))\n",
    "\n",
    "            fake_images = self.generator(random_latent_vectors)\n",
    "\n",
    "            fake_pred = self.critic(fake_images.detach())\n",
    "            real_pred = self.critic(real_images)\n",
    "\n",
    "\n",
    "            c_wass_loss = torch.mean(fake_pred) - torch.mean(real_pred)\n",
    "\n",
    "            c_gp = self.gradient_penalty(batch_size, real_images, fake_images.detach())\n",
    "\n",
    "            c_loss = c_wass_loss + self.gp_weight * c_gp\n",
    "            \n",
    "            c_loss.backward()\n",
    "            self.critic_opt.step()\n",
    "   \n",
    "        self.generator_opt.zero_grad()\n",
    "\n",
    "        random_latent_vector = torch.randn(size = (batch_size, self.latent_dim))\n",
    "        fake_images = self.generator(random_latent_vector)\n",
    "        fake_predictions = self.critic(fake_images)\n",
    "        g_loss = -1.0 * torch.mean(fake_predictions)\n",
    "\n",
    "        g_loss.backward()\n",
    "        self.generator_opt.step()\n",
    "        self.scheduler_critic.step()\n",
    "\n",
    "        print('c_loss is  {}'.format(c_loss))\n",
    "        print('g_loss is  {}'.format(g_loss))\n",
    "        print('c_gp is  {}'.format(c_gp))\n",
    "        print('c_wass_loss is  {}'.format(c_wass_loss))\n",
    "\n",
    "\n",
    "\n",
    "        return (c_loss, g_loss, c_gp, c_wass_loss)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
